{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f678b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code with autotune\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "#XLA Activating\n",
    "tf.config.optimizer.set_jit(True) # وقتی منسبه که سایز ورودی همه بچ ها ثابت باشه..مثلا همش 224*224 باشه ولی در غیر این صورت نه!\n",
    "\n",
    "# Define the train and validation folder paths\n",
    "train_folder = 'C:/Users/salir/OneDrive/Desktop/catvsdogs/train'\n",
    "val_folder = 'C:/Users/salir/OneDrive/Desktop/catvsdogs/train'\n",
    "\n",
    "# Function to preprocess images with augmentation\n",
    "def preprocess_image_aug_norm(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "  # Data augmentation\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "  # Normalize using VGG16 preprocessing\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Function to preprocess images without augmentation\n",
    "\n",
    "#We use tf.function primarily on functions that involve TensorFlow operations. These are the instructions that involve lots of calculations, like processing images or making predictions with a neural network.\n",
    "\n",
    "#When we add @tf.function before a function definition, we're telling TensorFlow to convert that function into a special format called a graph. This graph is optimized for faster execution, especially on GPUs or TPUs.\n",
    "\n",
    "#For other calculations that don't involve TensorFlow operations, like simple arithmetic or basic Python functions, we don't need to use tf.function. That's because these calculations are already pretty fast and efficient in regular Python.\n",
    "\n",
    "#So, in summary, we use tf.function on functions that involve TensorFlow operations to speed up those specific parts of our code, while leaving other calculations as they are since they're already efficient. It's like using a turbo boost for the parts of our code that need it most!\n",
    "\n",
    "#tf.function Activation\n",
    "@tf.function\n",
    "def preprocess_image_norm(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Load and preprocess the training dataset with augmentation\n",
    "\n",
    "#num_parrarel_calls Actiavtion to activate treds of CPU\n",
    "#prefetch Activation to import next batch pararelly while training\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files(train_folder + '/*/*')\n",
    "train_dataset = train_dataset.map(lambda x: (x, tf.strings.split(x, os.path.sep)[-2] == 'cat'),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.map(lambda x, y: (preprocess_image_aug_norm(x, y)), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train_dataset.batch(128)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Load and preprocess the validation dataset without augmentation\n",
    "val_dataset = tf.data.Dataset.list_files(val_folder + '/*/*')\n",
    "#\n",
    "val_dataset = val_dataset.map(lambda x: (x, tf.strings.split(x, os.path.sep)[-2] == 'cat'),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#or\n",
    "#def get_label(filepath):\n",
    "  #subdirectory = tf.strings.split(filepath, os.path.sep)[-2]\n",
    "  #return filepath, subdirectory == 'cat'\n",
    "  #train_dataset = train_dataset.map(get_label)\n",
    "   \n",
    "val_dataset = val_dataset.map(lambda x, y: (preprocess_image_norm(x, y)), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(128)\n",
    "val_dataset = val_dataset.cache()# به شرطی که دیتا نوی رم جا بشه و خیلی وریشن نداشته باشه.برای دیتای ترین و آوگمنتیشن خیلی مناسب نیست\n",
    "#بعد از اینکه دیتای ولیدیشن رو کش کردیم و قبل از اینکه پری فچ کنیم، دیتا رو کش میکنیم\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE) #prefetch next batch while training\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of VGG16\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freeze base layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with a specified learning rate\n",
    "learning_rate = 0.1\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac073e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b483e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
